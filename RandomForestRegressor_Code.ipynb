{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, random_feature_fraction=0.5):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.random_feature_fraction = random_feature_fraction\n",
    "        self.tree = None\n",
    "        self.feature_importances = None # Opsional\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.feature_importances = np.zeros(X.shape[1])\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        num_samples, num_features = X.shape\n",
    "        unique_targets = np.unique(y)\n",
    "\n",
    "        if len(unique_targets) == 1:\n",
    "            return unique_targets[0]\n",
    "        if num_samples < self.min_samples_split:\n",
    "            return np.mean(y) if len(y) > 0 else 0\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return np.mean(y) if len(y) > 0 else 0\n",
    "\n",
    "        feature_indices = np.random.choice(num_features, int(self.random_feature_fraction * num_features), replace=False)\n",
    "\n",
    "        best_split = self._best_split(X, y, feature_indices)\n",
    "        if best_split is None:\n",
    "            return np.mean(y) if len(y) > 0 else 0\n",
    "\n",
    "        left_mask, right_mask = self._split_data(X[:, best_split['feature']], best_split['value'])\n",
    "\n",
    "        left_target, right_target = y[left_mask], y[right_mask]\n",
    "        mse_before = self._calculate_mse(y, y)\n",
    "        mse_after = self._calculate_mse(left_target, right_target)\n",
    "        reduction_in_mse = mse_before - mse_after\n",
    "\n",
    "        self.feature_importances[best_split['feature']] += reduction_in_mse\n",
    "\n",
    "        left_tree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "\n",
    "        return {\n",
    "            'feature': best_split['feature'],\n",
    "            'value': best_split['value'],\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "\n",
    "    def _best_split(self, X, y, feature_indices):\n",
    "        best_mse = float('inf')\n",
    "        best_split = None\n",
    "\n",
    "        for feature in feature_indices:    \n",
    "            values = np.unique(X[:, feature])    \n",
    "            for value in values:        \n",
    "                left_mask, right_mask = self._split_data(X[:, feature], value)\n",
    "                        \n",
    "                if len(left_mask) == 0 or len(right_mask) == 0:\n",
    "                    continue\n",
    "        \n",
    "                mse = self._calculate_mse(y[left_mask], y[right_mask])        \n",
    "                if mse < best_mse:\n",
    "                    best_mse = mse\n",
    "                    best_split = {'feature': feature, 'value': value}\n",
    "        \n",
    "        return best_split\n",
    "\n",
    "    def _split_data(self, feature_column, value):\n",
    "        left_mask = feature_column <= value\n",
    "        right_mask = ~left_mask\n",
    "        return left_mask, right_mask\n",
    "\n",
    "    def _calculate_mse(self, left_target, right_target):\n",
    "        if len(left_target) == 0 or len(right_target) == 0:\n",
    "            return float('inf')\n",
    "        left_mse = np.mean((left_target - np.mean(left_target)) ** 2) if len(left_target) > 0 else 0\n",
    "        right_mse = np.mean((right_target - np.mean(right_target)) ** 2) if len(right_target) > 0 else 0\n",
    "        return (len(left_target) * left_mse + len(right_target) * right_mse) / (len(left_target) + len(right_target))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_single(x, self.tree) for x in X])\n",
    "\n",
    "    def _predict_single(self, x, tree):\n",
    "        if isinstance(tree, dict):\n",
    "            if x[tree['feature']] <= tree['value']:\n",
    "                return self._predict_single(x, tree['left'])\n",
    "            else:\n",
    "                return self._predict_single(x, tree['right'])\n",
    "        else:\n",
    "            return tree\n",
    "\n",
    "class RandomForestRegressor:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, random_feature_fraction=0.5):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.random_feature_fraction = random_feature_fraction\n",
    "        self.trees = []\n",
    "        self.feature_importances_ = None # Opsional\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        feature_importances = np.zeros(X.shape[1])\n",
    "        for _ in range(self.n_estimators):\n",
    "    \n",
    "            bootstrap_indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_bootstrap = X[bootstrap_indices]\n",
    "            y_bootstrap = y[bootstrap_indices]\n",
    "\n",
    "            tree = DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                random_feature_fraction=self.random_feature_fraction\n",
    "            )\n",
    "            tree.fit(X_bootstrap, y_bootstrap)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "            feature_importances += tree.feature_importances\n",
    "        self.feature_importances_ = feature_importances / self.n_estimators\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.mean(tree_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample:\n",
      "      price  bed  bath  acre_lot  house_size  state_number\n",
      "0  480000.0  3.0   3.0      0.08      1648.0             1\n",
      "1  932995.0  2.0   3.0      0.15      2045.0             1\n",
      "2  525000.0  5.0   3.0      0.14      2616.0             1\n",
      "3  315000.0  2.0   2.0      0.21      1633.0             1\n",
      "4  650000.0  4.0   3.0      0.21      2577.0             1\n",
      "\n",
      "Training set size: 16000\n",
      "Test set size: 4000\n",
      "\n",
      "Sample comparison (True vs Predicted on Test Set):\n",
      "   True Price  Predicted Price\n",
      "0    147000.0        231632.70\n",
      "1    639000.0        276075.32\n",
      "2    829900.0        848995.11\n",
      "3    549900.0        487780.71\n",
      "4    785000.0        303893.97\n",
      "5   1495000.0        852630.52\n",
      "6    710000.0        696790.83\n",
      "7    535000.0        450191.83\n",
      "8    585000.0        537146.01\n",
      "9   2100000.0       1424114.90\n",
      "\n",
      "Model Evaluation Metrics on Test Set:\n",
      "R² Score: 0.4218\n",
      "Mean Squared Error (MSE): 239696292373.2661\n",
      "Mean Absolute Error (MAE): 244041.2767\n",
      "Feature Importances: [3.43174822e+13 5.14357021e+13 7.76350063e+13 6.13911977e+13\n",
      " 3.23850830e+13]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "data = pd.read_csv(\"Realtor20k-Sample.csv\")\n",
    "\n",
    "print(\"Data sample:\")\n",
    "print(data.head())\n",
    "\n",
    "X = data[['bed', 'bath', 'acre_lot', 'house_size', 'state_number']].values\n",
    "y = data['price'].values\n",
    "\n",
    "def train_test_split(X, y, test_size=0.2):\n",
    "\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(\"\\nTraining set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=5, random_feature_fraction=0.4)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = rf.predict(X_test)\n",
    "y_test_pred_rounded = np.round(y_test_pred, 2)\n",
    "\n",
    "comparison_test = pd.DataFrame({\n",
    "    'True Price': y_test,\n",
    "    'Predicted Price': y_test_pred_rounded\n",
    "})\n",
    "\n",
    "print(\"\\nSample comparison (True vs Predicted on Test Set):\")\n",
    "print(comparison_test.head(10))\n",
    "\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nModel Evaluation Metrics on Test Set:\")\n",
    "print(f\"R² Score: {r2_test:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_test:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_test:.4f}\")\n",
    "\n",
    "print(\"Feature Importances:\", rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(rf, 'RandomForest_Model-20K_Data.joblib')\n",
    "\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "loaded_rf = joblib.load('RandomForest_Model-20K.joblib')\n",
    "\n",
    "print(\"Model loaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
